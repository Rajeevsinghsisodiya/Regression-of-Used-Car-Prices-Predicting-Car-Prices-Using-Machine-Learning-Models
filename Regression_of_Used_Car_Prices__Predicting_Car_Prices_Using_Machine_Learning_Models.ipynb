{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Project Title: Regression of Used Car Prices\" Predicting Car Prices Using Machine Learning Models\"\n",
        "\n",
        "Contributor: Rajeev Singh Sisodiya\n",
        "\n",
        "#Project Overview:\n",
        "The goal of this project is to predict the prices of used cars based on various car attributes using advanced regression techniques. This problem is part of the 2024 Kaggle Playground Series, where datasets are designed for practicing and sharpening machine learning skills. The dataset includes attributes such as engine type, cylinder count, horsepower, and other characteristics.\n",
        "\n",
        "The solution involves:\n",
        "\n",
        "Data preprocessing (handling missing values, feature extraction, and scaling).\n",
        "Feature engineering (extracting details like engine displacement, cylinder configuration, and transmission type).\n",
        "Implementing and comparing different machine learning\n",
        "\n",
        "models, including:\n",
        "\n",
        "XGBoost (XGBRegressor)\n",
        "\n",
        "LightGBM (LGBMRegressor)\n",
        "\n",
        "Voting Regressor (combining the predictions of XGBoost and LightGBM)\n",
        "\n",
        "By employing these models, we aim to minimize prediction errors (measured by RMSE) and maximize prediction accuracy (measured by R² score). After model evaluation, predictions on test data are submitted in the form of a CSV file.\n",
        "\n",
        "To integrate modern machine learning techniques like Artificial Neural Networks (ANN), Recurrent Neural Networks (RNN), Computer Vision, and Generative AI into the car price prediction project, we can enhance our pipeline with these techniques, focusing on different aspects of the data.\n",
        "\n",
        "ANN for Tabular Data Prediction:\n",
        "We can use a simple ANN model for structured data prediction tasks.\n",
        "\n",
        "RNN for Time Series Features:\n",
        "If any temporal data (like model_year) can be considered as a time series feature, we can use RNN to model dependencies over time.\n",
        "\n",
        "Computer Vision for Image Processing (if applicable): If the dataset contains images (e.g., car pictures), we can use convolutional neural networks (CNN) for image analysis.\n",
        "\n",
        "Generative AI for Data Augmentation:\n",
        "We can employ generative models to create synthetic data for training if the dataset is small.\n",
        "\n",
        "#Key Steps:\n",
        "Feature Engineering:\n",
        "Extracting numerical values (horsepower, cylinder count) from text-based columns (like engine).\n",
        "Handling missing values and scaling the data appropriately.\n",
        "\n",
        "Modeling Approach:\n",
        "Training and evaluating advanced ensemble methods such as XGBoost and LightGBM.\n",
        "Using a Voting Regressor to blend the predictions from both models to improve accuracy."
      ],
      "metadata": {
        "id": "kt7Bbo-9Pl7y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries"
      ],
      "metadata": {
        "id": "_AjWbcZnLKwS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import copy\n",
        "import re\n",
        "from datetime import date\n",
        "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.ensemble import IsolationForest, VotingRegressor\n",
        "import xgboost as xgb\n",
        "from lightgbm import LGBMRegressor\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "\n"
      ],
      "metadata": {
        "id": "kVkSRbGdLM85"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for GPU\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ozl2PNULZFb",
        "outputId": "4f929ffc-166f-412c-92cf-68dbf8b6cc13"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Data\n",
        "train = pd.read_csv('/content/train.csv')\n",
        "test = pd.read_csv('/content/test.csv')\n"
      ],
      "metadata": {
        "id": "sQghJkYyLgVi"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Deep Copy\n",
        "df_train = copy.deepcopy(train)\n",
        "df_test = copy.deepcopy(test)\n"
      ],
      "metadata": {
        "id": "Cyz42yBvLlpX"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display object type columns and their values\n",
        "for col in df_train.select_dtypes(include='object'):\n",
        "    print(col)\n",
        "    print(df_train[col].nunique())\n",
        "    print(df_train[col].unique())\n",
        "    print('-----------------------------------------')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Zzg6_fpLq6A",
        "outputId": "270fc960-257a-46b1-8834-575959b79ee3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "brand\n",
            "57\n",
            "['MINI' 'Lincoln' 'Chevrolet' 'Genesis' 'Mercedes-Benz' 'Audi' 'Ford'\n",
            " 'BMW' 'Tesla' 'Cadillac' 'Land' 'GMC' 'Toyota' 'Hyundai' 'Volvo'\n",
            " 'Volkswagen' 'Buick' 'Rivian' 'RAM' 'Hummer' 'Alfa' 'INFINITI' 'Jeep'\n",
            " 'Porsche' 'McLaren' 'Honda' 'Lexus' 'Dodge' 'Nissan' 'Jaguar' 'Acura'\n",
            " 'Kia' 'Mitsubishi' 'Rolls-Royce' 'Maserati' 'Pontiac' 'Saturn' 'Bentley'\n",
            " 'Mazda' 'Subaru' 'Ferrari' 'Aston' 'Lamborghini' 'Chrysler' 'Lucid'\n",
            " 'Lotus' 'Scion' 'smart' 'Karma' 'Plymouth' 'Suzuki' 'FIAT' 'Saab'\n",
            " 'Bugatti' 'Mercury' 'Polestar' 'Maybach']\n",
            "-----------------------------------------\n",
            "model\n",
            "1897\n",
            "['Cooper S Base' 'LS V8' 'Silverado 2500 LT' ... 'e-Golf SE'\n",
            " 'Integra w/A-Spec Tech Package' 'IONIQ Plug-In Hybrid SEL']\n",
            "-----------------------------------------\n",
            "fuel_type\n",
            "7\n",
            "['Gasoline' 'E85 Flex Fuel' nan 'Hybrid' 'Diesel' 'Plug-In Hybrid' '–'\n",
            " 'not supported']\n",
            "-----------------------------------------\n",
            "engine\n",
            "1117\n",
            "['172.0HP 1.6L 4 Cylinder Engine Gasoline Fuel'\n",
            " '252.0HP 3.9L 8 Cylinder Engine Gasoline Fuel'\n",
            " '320.0HP 5.3L 8 Cylinder Engine Flex Fuel Capability' ...\n",
            " '78.0HP 1.2L 3 Cylinder Engine Gasoline Fuel'\n",
            " '139.0HP 1.6L 4 Cylinder Engine Plug-In Electric/Gas'\n",
            " '313.0HP 2.0L 4 Cylinder Engine Plug-In Electric/Gas']\n",
            "-----------------------------------------\n",
            "transmission\n",
            "52\n",
            "['A/T' 'Transmission w/Dual Shift Mode' '7-Speed A/T' '8-Speed A/T'\n",
            " '10-Speed Automatic' '1-Speed A/T' '6-Speed A/T' '10-Speed A/T'\n",
            " '9-Speed A/T' '8-Speed Automatic' '9-Speed Automatic' '5-Speed A/T'\n",
            " 'Automatic' '7-Speed Automatic with Auto-Shift' 'CVT Transmission'\n",
            " '5-Speed M/T' 'M/T' '6-Speed M/T' '6-Speed Automatic' '4-Speed Automatic'\n",
            " '7-Speed M/T' '2-Speed A/T' '1-Speed Automatic' 'Automatic CVT'\n",
            " '4-Speed A/T' '6-Speed Manual' 'Transmission Overdrive Switch'\n",
            " '8-Speed Automatic with Auto-Shift' '7-Speed Manual' '7-Speed Automatic'\n",
            " '9-Speed Automatic with Auto-Shift' '6-Speed Automatic with Auto-Shift'\n",
            " '6-Speed Electronically Controlled Automatic with O' 'F' 'CVT-F'\n",
            " '8-Speed Manual' 'Manual' '–' '2' '6 Speed At/Mt' '5-Speed Automatic'\n",
            " '2-Speed Automatic' '8-SPEED A/T' '7-Speed' 'Variable'\n",
            " 'Single-Speed Fixed Gear' '8-SPEED AT'\n",
            " '10-Speed Automatic with Overdrive' '7-Speed DCT Automatic'\n",
            " 'SCHEDULED FOR OR IN PRODUCTION' '6-Speed' '6 Speed Mt']\n",
            "-----------------------------------------\n",
            "ext_col\n",
            "319\n",
            "['Yellow' 'Silver' 'Blue' 'Black' 'White' 'Snowflake White Pearl Metallic'\n",
            " 'Gray' 'Green' 'Santorini Black Metallic' 'Purple'\n",
            " 'Ebony Twilight Metallic' 'Red' 'Magnetite Black Metallic'\n",
            " 'Diamond Black' 'Vega Blue' 'Beige' 'Gold' 'Platinum White Pearl'\n",
            " 'Metallic' 'White Frost Tri-Coat' 'Firecracker Red Clearcoat'\n",
            " 'Phytonic Blue Metallic' 'Blu' 'Orange' 'Brown'\n",
            " 'Brilliant Silver Metallic' 'Black Raven' 'Black Clearcoat' 'Firenze Red'\n",
            " 'Agate Black Metallic' 'Glacial White Pearl' 'Majestic Plum Metallic'\n",
            " 'designo Diamond White Metallic' 'Oxford White' 'Black Sapphire Metallic'\n",
            " 'Mythos Black' 'Granite Crystal Clearcoat Metallic'\n",
            " 'White Diamond Tri-Coat' 'Magnetite Gray Metallic'\n",
            " 'Carpathian Grey Premium Metallic' 'designo Diamond White Bright'\n",
            " 'Phantom Black Pearl Effect / Black Roof' 'Nebula Gray Pearl'\n",
            " 'Deep Crystal Blue Mica' 'Flame Red Clearcoat' 'Lunar Blue Metallic'\n",
            " 'Bright White Clearcoat' 'Rapid Red Metallic Tinted Clearcoat' 'Caviar'\n",
            " 'Dark Ash Metallic' 'Velvet Red Pearlcoat' 'Silver Zynith' 'Super Black'\n",
            " 'Antimatter Blue Metallic' 'Dark Moon Blue Metallic' 'Summit White'\n",
            " 'Ebony Black' '–' 'Black Cherry' 'Delmonico Red Pearlcoat'\n",
            " 'Platinum Quartz Metallic' 'Ultra White' 'Python Green'\n",
            " 'Garnet Red Metallic' 'Snow White Pearl' 'Cajun Red Tintcoat'\n",
            " 'Midnight Black Metallic' 'Diamond White' 'Mythos Black Metallic'\n",
            " 'Soul Red Crystal Metallic' 'Atomic Silver' 'Obsidian'\n",
            " 'Magnetic Metallic' 'Twilight Blue Metallic' 'Star White' 'Stormy Sea'\n",
            " 'Tango Red Metallic' 'Hyper Red' 'Portofino Gray'\n",
            " 'MANUFAKTUR Diamond White Bright' 'Snowflake White Pearl'\n",
            " 'Patriot Blue Pearlcoat' 'Tungsten Metallic' 'Chronos Gray Metallic'\n",
            " 'Silver Ice Metallic' 'Daytona Gray Pearl Effect'\n",
            " 'Ruby Red Metallic Tinted Clearcoat' 'Alpine White' 'Eminent White Pearl'\n",
            " 'Manhattan Noir Metallic' 'Quicksilver Metallic' 'Stellar Black Metallic'\n",
            " 'Sparkling Silver' 'Blueprint' 'Crystal Black Silica' 'Black Noir Pearl'\n",
            " 'Arancio Borealis' 'Typhoon Gray' 'Ibis White' 'Graphite Grey'\n",
            " 'Mineral White' 'Midnight Black' 'Northsky Blue Metallic' 'Alta White'\n",
            " 'Brilliant Black' 'Jet Black Mica'\n",
            " 'Daytona Gray Pearl Effect w/ Black Roof' 'Redline Red'\n",
            " 'Glacier Silver Metallic' 'Magnetic Black' 'Chronos Gray'\n",
            " 'Red Quartz Tintcoat' 'Nero Noctis' 'Firenze Red Metallic'\n",
            " 'Iridescent Pearl Tricoat' 'Twilight Black' 'Radiant Red Metallic II'\n",
            " 'Blue Metallic' 'Glacier White' 'Daytona Gray' 'Rosso Mars Metallic'\n",
            " 'Wolf Gray' 'Santorin Black' 'Designo Magno Matte'\n",
            " 'Emerald Green Metallic' 'Ruby Flare Pearl' 'Lunar Silver Metallic'\n",
            " 'Eiger Grey Metallic' 'Quartzite Grey Metallic' 'Barcelona Red'\n",
            " 'Beluga Black' 'Matador Red Metallic' 'Billet Silver Metallic Clearcoat'\n",
            " 'Anodized Blue Metallic' 'Black Forest Green' 'Ice Silver Metallic'\n",
            " 'Sandstone Metallic' 'Magnetic Gray Clearcoat' 'Crystal Black Pearl'\n",
            " 'Pacific Blue Metallic' 'Stone Gray Metallic' 'Iconic Silver Metallic'\n",
            " 'Dark Sapphire' 'Onyx' 'Aventurine Green Metallic' 'China Blue'\n",
            " 'Majestic Black Pearl' 'Midnight Silver Metallic' 'Sting Gray Clearcoat'\n",
            " 'Glacier Blue Metallic' 'BLACK' 'Chalk' 'Dark Matter Metallic'\n",
            " 'Infrared Tintcoat' 'Iridium Metallic' 'Fuji White' 'Alfa White'\n",
            " 'Kodiak Brown Metallic' 'Aurora Black' 'Onyx Black'\n",
            " 'Nightfall Gray Metallic' 'Obsidian Black Metallic' 'Phantom Black'\n",
            " 'Remington Red Metallic' 'designo Diamond White' 'Lizard Green'\n",
            " 'Rosso Corsa' 'Shadow Gray Metallic' 'Florett Silver' 'Quartz White'\n",
            " 'DB Black Clearcoat' 'Yulong White' 'Eiger Grey' 'Custom Color'\n",
            " 'Electric Blue Metallic' 'Tempest' 'Lunar Rock' 'Mosaic Black Metallic'\n",
            " 'Gecko Pearlcoat' 'White Clearcoat' 'BLU ELEOS'\n",
            " 'Granite Crystal Metallic Clearcoat' 'Rich Garnet Metallic'\n",
            " 'Graphite Grey Metallic' 'Bianco Icarus Metallic' 'Satin Steel Metallic'\n",
            " 'BLUE' 'Moonlight Cloud' 'Matador Red Mica' 'Emin White'\n",
            " 'Machine Gray Metallic' 'White Platinum Tri-Coat Metallic'\n",
            " 'Cobra Beige Metallic' 'Cayenne Red Tintcoat' 'Shoreline Blue Pearl'\n",
            " 'Vik Black' 'Shimmering Silver' 'Bianco Monocerus'\n",
            " 'Carbonized Gray Metallic' 'Carrara White Metallic' 'Dark Slate Metallic'\n",
            " 'Dark Graphite Metallic' 'Sonic Silver Metallic'\n",
            " 'White Knuckle Clearcoat' 'Titanium Silver' 'Anthracite Blue Metallic'\n",
            " 'Black Obsidian' 'Polymetal Gray Metallic' 'Orca Black Metallic'\n",
            " 'Wind Chill Pearl' 'Blue Reflex Mica' 'Dark Moss'\n",
            " 'Selenite Grey Metallic' 'Kemora Gray Metallic' 'Nightfall Mica'\n",
            " 'Liquid Platinum' 'Mountain Air Metallic' 'Kinetic Blue'\n",
            " 'Santorini Black' 'Carbon Black Metallic' 'Gentian Blue Metallic'\n",
            " 'Red Multi' 'Super White' 'Pearl White' 'Typhoon Gray Metallic'\n",
            " 'Navarra Blue Metallic' 'Bianco Isis' 'Navarra Blue'\n",
            " 'Volcano Grey Metallic' 'Arctic Gray Metallic' 'Pure White' 'Baltic Gray'\n",
            " 'Glacier White Metallic' 'Frozen Dark Silver Metallic'\n",
            " 'Magnetic Gray Metallic' 'Gun Metallic' 'Siren Red Tintcoat'\n",
            " 'Deep Blue Metallic' 'Cirrus Silver Metallic' 'Deep Black Pearl Effect'\n",
            " 'Granite' 'Sunset Drift Chromaflair' 'Oryx White Prl'\n",
            " 'Dark Gray Metallic' 'Bayside Blue' 'Pink' 'Ice' 'Mango Tango Pearlcoat'\n",
            " 'Burnished Bronze Metallic' 'Verde' 'Arctic White'\n",
            " 'Portofino Blue Metallic' 'Dazzling White' 'Nero Daytona'\n",
            " 'Nautical Blue Pearl' 'Imperial Blue Metallic' 'Vulcano Black Metallic'\n",
            " 'Silver Radiance' 'Hellayella Clearcoat' 'Jungle Green' 'C / C' 'Yulong'\n",
            " 'Pristine White' 'Silky Silver' 'Caspian Blue' 'Sangria Red'\n",
            " 'Donington Grey Metallic' 'Apex Blue' 'Rift Metallic' 'Fountain Blue'\n",
            " 'Balloon White' 'Matte White' 'Frozen White' 'Pacific Blue' 'Rosso'\n",
            " 'Ironman Silver' 'Octane Red Pearlcoat' 'Selenite Gray Metallic'\n",
            " 'Hydro Blue Pearlcoat' 'Ingot Silver Metallic' 'Quartz Blue Pearl'\n",
            " 'Lunare White Metallic' 'Ember Pearlcoat' 'Brands Hatch Gray Metallic'\n",
            " 'Navarre Blue' 'Midnight Blue Metallic' 'Shadow Black' 'Go Mango!'\n",
            " 'Maximum Steel Metallic' 'Silver Flare Metallic'\n",
            " 'Billet Clearcoat Metallic' 'Hampton Gray' 'Red Obsession' 'Silver Mist'\n",
            " 'Scarlet Ember' 'Crimson Red Tintcoat' 'Tan' 'Isle of Man Green Metallic'\n",
            " 'Crystal Black' 'Glacier' 'Iridium Silver Metallic'\n",
            " 'Bronze Dune Metallic' 'Maroon' 'Platinum Gray Metallic' 'Passion Red'\n",
            " 'Silician Yellow' 'Volcanic Orange' 'Crystal White Pearl' 'Reflex Silver'\n",
            " 'Blue Caelum' 'Thunder Gray' 'Ultra Black' 'Indus Silver' 'Horizon Blue'\n",
            " 'Grigio Nimbus' 'Carpathian Grey' 'Ametrin Metallic' 'Jupiter Red'\n",
            " 'GT SILVER']\n",
            "-----------------------------------------\n",
            "int_col\n",
            "156\n",
            "['Gray' 'Beige' 'Black' '–' 'Blue' 'White' 'Red' 'Brown' 'Dark Galvanized'\n",
            " 'Parchment.' 'Boulder' 'Orange' 'Medium Earth Gray' 'Ebony'\n",
            " 'Canberra Beige' 'Jet Black' 'Silver' 'Light Platinum / Jet Black'\n",
            " 'Macchiato/Magmagrey' 'Gold' 'Cloud' 'Rioja Red' 'Global Black' 'Green'\n",
            " 'Medium Stone' 'Navy Pier' 'Dark Ash' 'BLACK' 'Portland' 'Sandstone'\n",
            " 'Canberra Beige/Black' 'Diesel Gray / Black' 'Sarder Brown' 'Black Onyx'\n",
            " 'White / Brown' 'Black/Gun Metal' 'Slate' 'Satin Black'\n",
            " 'Macchiato Beige/Black' 'Charcoal' 'Black / Express Red' 'Cappuccino'\n",
            " 'Aragon Brown' 'Parchment' 'Oyster W/Contrast' 'Adrenaline Red' 'Ebony.'\n",
            " 'Shara Beige' 'Graystone' 'Pearl Beige' 'Nero Ade' 'Graphite'\n",
            " 'Tan/Ebony/Ebony' 'Charcoal Black' 'Medium Ash Gray' 'Ebony Black'\n",
            " 'Light Titanium' 'Sakhir Orange' 'Tan' 'Rock Gray' 'Brandy'\n",
            " 'Carbon Black' 'Amber' 'Black w/Red Stitching' 'Hotspur' 'Chateau' 'Ice'\n",
            " 'Deep Garnet' 'Blk' 'Grace White' 'Oyster/Black' 'Mesa' 'Espresso'\n",
            " 'Black/Graphite' 'Ebony / Ebony Accents' 'Tan/Ebony' 'Ceramic'\n",
            " 'Medium Dark Slate' 'Graphite w/Gun Metal' 'Obsidian Black'\n",
            " 'Cocoa / Dune' 'Roast' 'Yellow' 'Hotspur Hide' 'Gray w/Blue Bolsters'\n",
            " 'Chestnut' 'Saiga Beige' 'ORANGE' 'Charles Blue' 'Walnut' 'Ivory / Ebony'\n",
            " 'Caramel' 'Pimento Red w/Ebony' 'Saddle Brown' 'Dark Gray'\n",
            " 'Silk Beige/Espresso Brown' 'Black / Brown' 'Ebony/Light Oyster Stitch'\n",
            " 'Ebony / Pimento' 'Mistral Gray / Raven' 'Giallo Taurus / Nero Ade'\n",
            " 'Tension' 'Medium Pewter' 'Black / Saddle' 'Camel Leather'\n",
            " 'Black/Saddle Brown' 'Macchiato' 'Anthracite' 'Mocha' 'Whisper Beige'\n",
            " 'Titan Black / Quarzit' 'Sahara Tan' 'Porpoise' 'Black/Red' 'Titan Black'\n",
            " 'AMG Black' 'Deep Cypress' 'Light Slate' 'Red / Black' 'Beluga Hide'\n",
            " 'Tupelo' 'Gideon' 'Rhapsody Blue' 'Medium Light Camel' 'Almond Beige'\n",
            " 'Black / Gray' 'Nero' 'Agave Green' 'Deep Chestnut' 'Dark Auburn' 'Shale'\n",
            " 'Silk Beige/Black' 'BEIGE' 'Magma Red' 'Linen' 'Black / Stone Grey'\n",
            " 'Sand Beige' 'Red/Black' 'Bianco Polar' 'Light Gray' 'Platinum' 'Sport'\n",
            " 'Ash' 'Black / Graphite' 'Nougat Brown' 'Camel' 'Mountain Brown'\n",
            " 'Pimento / Ebony' 'Classic Red' 'Sakhir Orange/Black' 'Cobalt Blue'\n",
            " 'Very Light Cashmere' 'Kyalami Orange' 'Orchid' 'Beluga' 'WHITE']\n",
            "-----------------------------------------\n",
            "accident\n",
            "2\n",
            "['None reported' 'At least 1 accident or damage reported' nan]\n",
            "-----------------------------------------\n",
            "clean_title\n",
            "1\n",
            "['Yes' nan]\n",
            "-----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract engine features\n",
        "def extract_engine_features(df):\n",
        "    df['Horse_power'] = df['engine'].str.extract(r'(\\d+)\\.?\\d*HP').astype(float)\n",
        "    df['Engine_Displacement'] = df['engine'].str.extract(r'(\\d+\\.?\\d*)L').astype(float)\n",
        "    df['Cylinder_Count'] = df['engine'].str.extract(r'(\\d+) Cylinder ').astype(float)\n",
        "    return df\n",
        "\n",
        "df_train = extract_engine_features(df_train)\n",
        "df_test = extract_engine_features(df_test)\n"
      ],
      "metadata": {
        "id": "sPpWdzcrLxhO"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract engine details (cylinder config, turbocharger, engine type, fuel systems)\n",
        "cylinder_config = {'V', 'Flat', 'Straight'}\n",
        "Turbocharger = {'Turbo', 'Twin Turbo'}\n",
        "engine_type = {'Gasoline', 'Electric', 'Hybrid'}\n",
        "FUEL_SYSTEMS = {'MPFI', 'GDI', 'PDI', 'TFSI', 'DOHC', 'SOHC'}\n",
        "\n",
        "def extract_engine_components(df, component, keywords):\n",
        "    df[component] = df['engine'].apply(lambda x: next((kw for kw in keywords if kw in x), 'Nan'))\n",
        "    return df\n",
        "\n",
        "df_train = extract_engine_components(df_train, 'cylinder_config', cylinder_config)\n",
        "df_train = extract_engine_components(df_train, 'Turbocharger', Turbocharger)\n",
        "df_train = extract_engine_components(df_train, 'engine_type', engine_type)\n",
        "df_train = extract_engine_components(df_train, 'FUEL_SYSTEMS', FUEL_SYSTEMS)\n",
        "\n",
        "df_test = extract_engine_components(df_test, 'cylinder_config', cylinder_config)\n",
        "df_test = extract_engine_components(df_test, 'Turbocharger', Turbocharger)\n",
        "df_test = extract_engine_components(df_test, 'engine_type', engine_type)\n",
        "df_test = extract_engine_components(df_test, 'FUEL_SYSTEMS', FUEL_SYSTEMS)\n",
        "\n"
      ],
      "metadata": {
        "id": "yb65sPymL6Vy"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transmission extraction\n",
        "def extract_transmission(word):\n",
        "    def get_number():\n",
        "        n = re.findall('\\d+', str(word))\n",
        "        return n[0] if n else ''\n",
        "\n",
        "    if any(i in str(word) for i in ['AT', 'A/T', 'At/Mt', 'Automatic']):\n",
        "        return 'AT' + get_number()\n",
        "    elif 'CVT' in str(word):\n",
        "        return 'CVT' + get_number()\n",
        "    elif any(i in str(word) for i in ['Manual', 'M/T']):\n",
        "        return 'MT' + get_number()\n",
        "    else:\n",
        "        return 'other'\n",
        "\n",
        "df_train['new_transmission'] = df_train['transmission'].apply(extract_transmission)\n",
        "df_test['new_transmission'] = df_test['transmission'].apply(extract_transmission)\n",
        "\n"
      ],
      "metadata": {
        "id": "j65IlBOFMD5_"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop unnecessary columns\n",
        "df_train.drop(['engine', 'transmission', 'model'], axis=1, inplace=True)\n",
        "df_test.drop(['engine', 'transmission', 'model'], axis=1, inplace=True)\n"
      ],
      "metadata": {
        "id": "xXWcvwQnMKmn"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "source": [
        "# Handling missing values\n",
        "num_cols = df_train.select_dtypes(include='number').columns\n",
        "cat_cols = df_train.select_dtypes(include='object').columns\n",
        "\n",
        "num_imputer = SimpleImputer(strategy='mean')\n",
        "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
        "encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Check if 'price' column exists in df_test before applying transformations\n",
        "if 'price' in df_test.columns:\n",
        "    for col in num_cols:\n",
        "        df_train[col] = num_imputer.fit_transform(df_train[[col]])\n",
        "        df_test[col] = num_imputer.transform(df_test[[col]])\n",
        "        df_train[col] = scaler.fit_transform(df_train[[col]])\n",
        "        df_test[col] = scaler.transform(df_test[[col]])\n",
        "\n",
        "for col in cat_cols:\n",
        "    # Use single brackets and ravel to pass a 1D array to fit_transform\n",
        "    df_train[col] = cat_imputer.fit_transform(df_train[col].values.reshape(-1, 1)).ravel()\n",
        "    df_test[col] = cat_imputer.transform(df_test[col].values.reshape(-1, 1)).ravel()\n",
        "    df_train[col] = encoder.fit_transform(df_train[col].values.reshape(-1, 1)).ravel()\n",
        "    df_test[col] = encoder.transform(df_test[col].values.reshape(-1, 1)).ravel()"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "ThIS-6D8Mxm2"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "source": [
        "# Isolation Forest for outlier detection\n",
        "isolation_forest = IsolationForest(contamination=0.024, random_state=42)\n",
        "\n",
        "# Check for NaN values and handle them before fitting the model\n",
        "if df_train.isnull().values.any():\n",
        "  # Impute NaN values with the mean for numerical columns and most frequent for categorical columns\n",
        "  df_train.fillna(df_train.mean(numeric_only=True), inplace=True)\n",
        "  df_train.fillna(df_train.mode().iloc[0], inplace=True)\n",
        "\n",
        "x_train_labels = isolation_forest.fit_predict(df_train)\n",
        "normal_bool = x_train_labels != -1\n",
        "df_train = df_train[normal_bool]"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "Qjff2hS6NRA7"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Setup\n",
        "x_train, x_test, y_train, y_test = train_test_split(df_train.drop('price', axis=1), df_train['price'], test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "AY_IvAJ8Nbww"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# XGBoost and LightGBM model setup\n",
        "xgb_model = xgb.XGBRegressor(tree_method=\"hist\", device=\"cuda\", objective=\"reg:squarederror\", eval_metric=\"rmse\",\n",
        "                             random_state=42, colsample_bytree=0.45, learning_rate=0.025, max_depth=7, n_estimators=3000,\n",
        "                             reg_alpha=0.001, reg_lambda=0.001, min_child_weight=18, verbosity=0, enable_categorical=True)\n",
        "\n",
        "lgb_model = LGBMRegressor(n_epochs=1000, learning_rate=0.01, colsample_bytree=0.55, bagging_fraction=0.8, num_leaves=3072,\n",
        "                          min_child_samples=12, reg_lambda=64, max_bin=255, max_depth=10, reg_alpha=0, verbose=-1)\n"
      ],
      "metadata": {
        "id": "htnYBzxiNiG7"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Models\n",
        "xgb_model.fit(x_train, y_train)\n",
        "lgb_model.fit(x_train, y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "AE1XjgYHNnTw",
        "outputId": "f9f851f4-5996-4c87-81fb-58fa10c59ee6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LGBMRegressor(bagging_fraction=0.8, colsample_bytree=0.55, learning_rate=0.01,\n",
              "              max_bin=255, max_depth=10, min_child_samples=12, n_epochs=1000,\n",
              "              num_leaves=3072, reg_alpha=0, reg_lambda=64, verbose=-1)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMRegressor(bagging_fraction=0.8, colsample_bytree=0.55, learning_rate=0.01,\n",
              "              max_bin=255, max_depth=10, min_child_samples=12, n_epochs=1000,\n",
              "              num_leaves=3072, reg_alpha=0, reg_lambda=64, verbose=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMRegressor</label><div class=\"sk-toggleable__content\"><pre>LGBMRegressor(bagging_fraction=0.8, colsample_bytree=0.55, learning_rate=0.01,\n",
              "              max_bin=255, max_depth=10, min_child_samples=12, n_epochs=1000,\n",
              "              num_leaves=3072, reg_alpha=0, reg_lambda=64, verbose=-1)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Voting Regressor\n",
        "vtr = VotingRegressor(estimators=[('xgboost', xgb_model), ('lightgbm', lgb_model)])\n",
        "vtr.fit(x_train, y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "ELiX5AUTNv5y",
        "outputId": "b98b3309-3467-4a2e-c208-bcef68e96bbf"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VotingRegressor(estimators=[('xgboost',\n",
              "                             XGBRegressor(base_score=None, booster=None,\n",
              "                                          callbacks=None,\n",
              "                                          colsample_bylevel=None,\n",
              "                                          colsample_bynode=None,\n",
              "                                          colsample_bytree=0.45, device='cuda',\n",
              "                                          early_stopping_rounds=None,\n",
              "                                          enable_categorical=True,\n",
              "                                          eval_metric='rmse',\n",
              "                                          feature_types=None, gamma=None,\n",
              "                                          grow_policy=None,\n",
              "                                          importance_type=None,\n",
              "                                          interaction_constraints=None,\n",
              "                                          learni...\n",
              "                                          max_leaves=None, min_child_weight=18,\n",
              "                                          missing=nan,\n",
              "                                          monotone_constraints=None,\n",
              "                                          multi_strategy=None,\n",
              "                                          n_estimators=3000, n_jobs=None,\n",
              "                                          num_parallel_tree=None,\n",
              "                                          random_state=42, ...)),\n",
              "                            ('lightgbm',\n",
              "                             LGBMRegressor(bagging_fraction=0.8,\n",
              "                                           colsample_bytree=0.55,\n",
              "                                           learning_rate=0.01, max_bin=255,\n",
              "                                           max_depth=10, min_child_samples=12,\n",
              "                                           n_epochs=1000, num_leaves=3072,\n",
              "                                           reg_alpha=0, reg_lambda=64,\n",
              "                                           verbose=-1))])"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingRegressor(estimators=[(&#x27;xgboost&#x27;,\n",
              "                             XGBRegressor(base_score=None, booster=None,\n",
              "                                          callbacks=None,\n",
              "                                          colsample_bylevel=None,\n",
              "                                          colsample_bynode=None,\n",
              "                                          colsample_bytree=0.45, device=&#x27;cuda&#x27;,\n",
              "                                          early_stopping_rounds=None,\n",
              "                                          enable_categorical=True,\n",
              "                                          eval_metric=&#x27;rmse&#x27;,\n",
              "                                          feature_types=None, gamma=None,\n",
              "                                          grow_policy=None,\n",
              "                                          importance_type=None,\n",
              "                                          interaction_constraints=None,\n",
              "                                          learni...\n",
              "                                          max_leaves=None, min_child_weight=18,\n",
              "                                          missing=nan,\n",
              "                                          monotone_constraints=None,\n",
              "                                          multi_strategy=None,\n",
              "                                          n_estimators=3000, n_jobs=None,\n",
              "                                          num_parallel_tree=None,\n",
              "                                          random_state=42, ...)),\n",
              "                            (&#x27;lightgbm&#x27;,\n",
              "                             LGBMRegressor(bagging_fraction=0.8,\n",
              "                                           colsample_bytree=0.55,\n",
              "                                           learning_rate=0.01, max_bin=255,\n",
              "                                           max_depth=10, min_child_samples=12,\n",
              "                                           n_epochs=1000, num_leaves=3072,\n",
              "                                           reg_alpha=0, reg_lambda=64,\n",
              "                                           verbose=-1))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VotingRegressor</label><div class=\"sk-toggleable__content\"><pre>VotingRegressor(estimators=[(&#x27;xgboost&#x27;,\n",
              "                             XGBRegressor(base_score=None, booster=None,\n",
              "                                          callbacks=None,\n",
              "                                          colsample_bylevel=None,\n",
              "                                          colsample_bynode=None,\n",
              "                                          colsample_bytree=0.45, device=&#x27;cuda&#x27;,\n",
              "                                          early_stopping_rounds=None,\n",
              "                                          enable_categorical=True,\n",
              "                                          eval_metric=&#x27;rmse&#x27;,\n",
              "                                          feature_types=None, gamma=None,\n",
              "                                          grow_policy=None,\n",
              "                                          importance_type=None,\n",
              "                                          interaction_constraints=None,\n",
              "                                          learni...\n",
              "                                          max_leaves=None, min_child_weight=18,\n",
              "                                          missing=nan,\n",
              "                                          monotone_constraints=None,\n",
              "                                          multi_strategy=None,\n",
              "                                          n_estimators=3000, n_jobs=None,\n",
              "                                          num_parallel_tree=None,\n",
              "                                          random_state=42, ...)),\n",
              "                            (&#x27;lightgbm&#x27;,\n",
              "                             LGBMRegressor(bagging_fraction=0.8,\n",
              "                                           colsample_bytree=0.55,\n",
              "                                           learning_rate=0.01, max_bin=255,\n",
              "                                           max_depth=10, min_child_samples=12,\n",
              "                                           n_epochs=1000, num_leaves=3072,\n",
              "                                           reg_alpha=0, reg_lambda=64,\n",
              "                                           verbose=-1))])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>xgboost</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
              "             colsample_bylevel=None, colsample_bynode=None,\n",
              "             colsample_bytree=0.45, device=&#x27;cuda&#x27;, early_stopping_rounds=None,\n",
              "             enable_categorical=True, eval_metric=&#x27;rmse&#x27;, feature_types=None,\n",
              "             gamma=None, grow_policy=None, importance_type=None,\n",
              "             interaction_constraints=None, learning_rate=0.025, max_bin=None,\n",
              "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "             max_delta_step=None, max_depth=7, max_leaves=None,\n",
              "             min_child_weight=18, missing=nan, monotone_constraints=None,\n",
              "             multi_strategy=None, n_estimators=3000, n_jobs=None,\n",
              "             num_parallel_tree=None, random_state=42, ...)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lightgbm</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMRegressor</label><div class=\"sk-toggleable__content\"><pre>LGBMRegressor(bagging_fraction=0.8, colsample_bytree=0.55, learning_rate=0.01,\n",
              "              max_bin=255, max_depth=10, min_child_samples=12, n_epochs=1000,\n",
              "              num_leaves=3072, reg_alpha=0, reg_lambda=64, verbose=-1)</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions\n",
        "y_pred_xgb = xgb_model.predict(x_test)\n",
        "y_pred_lgb = lgb_model.predict(x_test)\n",
        "y_pred_vtr = vtr.predict(x_test)"
      ],
      "metadata": {
        "id": "FhdyRUn2OBqt"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "mse_xgb = np.sqrt(mean_squared_error(y_test, y_pred_xgb))\n",
        "mse_lgb = np.sqrt(mean_squared_error(y_test, y_pred_lgb))\n",
        "mse_vtr = np.sqrt(mean_squared_error(y_test, y_pred_vtr))"
      ],
      "metadata": {
        "id": "8pVurIL7OKnn"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"XGBoost MSE:\", mse_xgb)\n",
        "print(\"LightGBM MSE:\", mse_lgb)\n",
        "print(\"Voting Regressor MSE:\", mse_vtr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7kWLtgBOPQT",
        "outputId": "31df1c6f-78dc-45df-933e-09632b2a0de8"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost MSE: 55735.64240506938\n",
            "LightGBM MSE: 56244.16193475547\n",
            "Voting Regressor MSE: 55376.16028419031\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Submission File\n",
        "submission = pd.DataFrame({\n",
        "    'id': test['id'],\n",
        "    'price': vtr.predict(df_test)\n",
        "})\n",
        "submission.to_csv('submission.csv', index=False)"
      ],
      "metadata": {
        "id": "6k8WsqqMOVQ7"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's add an ANN model to your pipeline for used car price predictions, keeping the current XGBoost and LightGBM models for comparison.\n",
        "\n",
        "Steps:\n",
        "\n",
        "Prepare the data pipeline as you already did.\n",
        "\n",
        "Add an ANN model for the prediction task.\n",
        "\n",
        "Compare ANN performance with XGBoost and LightGBM."
      ],
      "metadata": {
        "id": "LEpF_urrSx6E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ANN Model\n",
        "def create_ann_model():\n",
        "    model = Sequential([\n",
        "        Dense(128, activation='relu', input_shape=(x_train.shape[1],)),\n",
        "        Dropout(0.2),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(0.2),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dense(1)\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "    return model\n",
        "\n",
        "ann_model = create_ann_model()\n",
        "ann_model.fit(scaler.fit_transform(x_train), y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# ANN Predictions\n",
        "y_pred_ann = ann_model.predict(scaler.transform(x_test))\n",
        "mse_ann = mean_squared_error(y_test, y_pred_ann)\n",
        "r2_ann = r2_score(y_test, y_pred_ann)\n",
        "\n",
        "print(\"ANN MSE:\", mse_ann)\n",
        "print(\"ANN R2 Score:\", r2_ann)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2VPh5qGOvDV",
        "outputId": "e362402e-baf6-4731-e4ba-8c4e4bda017e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m3681/3681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 4071098624.0000 - mae: 24393.2832 - val_loss: 2965001728.0000 - val_mae: 17404.6270\n",
            "Epoch 2/50\n",
            "\u001b[1m3681/3681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - loss: 2788294400.0000 - mae: 17484.9844 - val_loss: 2956114944.0000 - val_mae: 16880.9043\n",
            "Epoch 3/50\n",
            "\u001b[1m3681/3681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 7ms/step - loss: 2588393216.0000 - mae: 17379.8945 - val_loss: 2949027072.0000 - val_mae: 16856.8203\n",
            "Epoch 4/50\n",
            "\u001b[1m3681/3681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 3ms/step - loss: 2862849280.0000 - mae: 17539.0000 - val_loss: 2943825920.0000 - val_mae: 16835.7500\n",
            "Epoch 5/50\n",
            "\u001b[1m3681/3681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 2777673472.0000 - mae: 17425.4785 - val_loss: 2939969792.0000 - val_mae: 16866.0664\n",
            "Epoch 6/50\n",
            "\u001b[1m3681/3681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - loss: 3067645440.0000 - mae: 17523.7656 - val_loss: 2936968960.0000 - val_mae: 17402.4551\n",
            "Epoch 7/50\n",
            "\u001b[1m3681/3681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 3121282048.0000 - mae: 17674.0723 - val_loss: 2933517568.0000 - val_mae: 16764.5801\n",
            "Epoch 8/50\n",
            "\u001b[1m3681/3681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 2898999808.0000 - mae: 17616.6211 - val_loss: 2932577024.0000 - val_mae: 16766.6660\n",
            "Epoch 9/50\n",
            "\u001b[1m3681/3681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - loss: 2831056640.0000 - mae: 17186.9336 - val_loss: 2927897344.0000 - val_mae: 16892.0352\n",
            "Epoch 10/50\n",
            "\u001b[1m3681/3681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - loss: 2874580480.0000 - mae: 17397.0410 - val_loss: 2928279808.0000 - val_mae: 17347.7402\n",
            "Epoch 11/50\n",
            "\u001b[1m3681/3681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - loss: 2473970176.0000 - mae: 17305.3633 - val_loss: 2925995264.0000 - val_mae: 17144.1367\n",
            "Epoch 12/50\n",
            "\u001b[1m3681/3681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 6ms/step - loss: 3499442176.0000 - mae: 17652.4805 - val_loss: 2924997120.0000 - val_mae: 16955.9766\n",
            "Epoch 13/50\n",
            "\u001b[1m3681/3681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - loss: 2595612672.0000 - mae: 17069.2812 - val_loss: 2923117824.0000 - val_mae: 16797.0195\n",
            "Epoch 14/50\n",
            "\u001b[1m3681/3681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - loss: 2968417792.0000 - mae: 17479.5840 - val_loss: 2928380160.0000 - val_mae: 16324.8340\n",
            "Epoch 15/50\n",
            "\u001b[1m3681/3681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 5ms/step - loss: 2798560000.0000 - mae: 17175.0293 - val_loss: 2922006016.0000 - val_mae: 16630.0840\n",
            "Epoch 16/50\n",
            "\u001b[1m3681/3681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - loss: 3096222720.0000 - mae: 17443.4414 - val_loss: 2920959232.0000 - val_mae: 16877.5566\n",
            "Epoch 17/50\n",
            "\u001b[1m3681/3681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - loss: 3177450496.0000 - mae: 17431.1543 - val_loss: 2920880128.0000 - val_mae: 17072.8047\n",
            "Epoch 18/50\n",
            "\u001b[1m3681/3681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 2495862528.0000 - mae: 16920.4668 - val_loss: 2920795392.0000 - val_mae: 16541.3516\n",
            "Epoch 19/50\n",
            "\u001b[1m3681/3681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - loss: 3080714752.0000 - mae: 17427.0527 - val_loss: 2918984192.0000 - val_mae: 16650.1934\n",
            "Epoch 20/50\n",
            "\u001b[1m3681/3681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3ms/step - loss: 3178183936.0000 - mae: 17383.7461 - val_loss: 2918848768.0000 - val_mae: 16975.8105\n",
            "Epoch 21/50\n",
            "\u001b[1m3681/3681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 3053247232.0000 - mae: 17335.0176 - val_loss: 2916558080.0000 - val_mae: 16828.4570\n",
            "Epoch 22/50\n",
            "\u001b[1m3681/3681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - loss: 2733287936.0000 - mae: 17155.0527 - val_loss: 2917210112.0000 - val_mae: 16859.5723\n",
            "Epoch 23/50\n",
            "\u001b[1m3681/3681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 2521183744.0000 - mae: 17001.2188 - val_loss: 2917953280.0000 - val_mae: 17049.3203\n",
            "Epoch 24/50\n",
            "\u001b[1m3681/3681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - loss: 2873715200.0000 - mae: 17265.9141 - val_loss: 2915080960.0000 - val_mae: 16769.0078\n",
            "Epoch 25/50\n",
            "\u001b[1m3681/3681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - loss: 2792116224.0000 - mae: 17078.8809 - val_loss: 2916620032.0000 - val_mae: 16879.9043\n",
            "Epoch 26/50\n",
            "\u001b[1m3681/3681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - loss: 3181226752.0000 - mae: 17316.9316 - val_loss: 2919790592.0000 - val_mae: 17116.1914\n",
            "Epoch 27/50\n",
            "\u001b[1m3681/3681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - loss: 2525132800.0000 - mae: 17114.9199 - val_loss: 2916663040.0000 - val_mae: 16526.6719\n",
            "Epoch 28/50\n",
            "\u001b[1m3681/3681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - loss: 2849103104.0000 - mae: 17304.1328 - val_loss: 2914488832.0000 - val_mae: 16753.8789\n",
            "Epoch 29/50\n",
            "\u001b[1m3681/3681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - loss: 2572823808.0000 - mae: 17231.2578 - val_loss: 2914937600.0000 - val_mae: 16754.4355\n",
            "Epoch 30/50\n",
            "\u001b[1m3681/3681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - loss: 2865823488.0000 - mae: 17418.0723 - val_loss: 2915359744.0000 - val_mae: 17035.3809\n",
            "Epoch 31/50\n",
            "\u001b[1m3681/3681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 2734535680.0000 - mae: 17079.0156 - val_loss: 2916738048.0000 - val_mae: 16566.0762\n",
            "Epoch 32/50\n",
            "\u001b[1m3681/3681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 7ms/step - loss: 3075104512.0000 - mae: 17271.6328 - val_loss: 2921432064.0000 - val_mae: 16171.0537\n",
            "Epoch 33/50\n",
            "\u001b[1m3681/3681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - loss: 3317024768.0000 - mae: 17224.0664 - val_loss: 2928615424.0000 - val_mae: 17695.3223\n",
            "Epoch 34/50\n",
            "\u001b[1m3681/3681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - loss: 3309491712.0000 - mae: 17492.2598 - val_loss: 2915346432.0000 - val_mae: 16455.9668\n",
            "Epoch 35/50\n",
            "\u001b[1m3681/3681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - loss: 2629635072.0000 - mae: 17038.0195 - val_loss: 2914834432.0000 - val_mae: 16508.1016\n",
            "Epoch 36/50\n",
            "\u001b[1m3681/3681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 5ms/step - loss: 3346876160.0000 - mae: 17674.0449 - val_loss: 2914549504.0000 - val_mae: 16423.5332\n",
            "Epoch 37/50\n",
            "\u001b[1m3681/3681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - loss: 3234916096.0000 - mae: 17083.5820 - val_loss: 2913137664.0000 - val_mae: 16783.6367\n",
            "Epoch 38/50\n",
            "\u001b[1m3681/3681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 2989632768.0000 - mae: 17349.0371 - val_loss: 2916993280.0000 - val_mae: 16447.2090\n",
            "Epoch 39/50\n",
            "\u001b[1m3681/3681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - loss: 2415450368.0000 - mae: 16701.1484 - val_loss: 2915395840.0000 - val_mae: 17167.3906\n",
            "Epoch 40/50\n",
            "\u001b[1m3681/3681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - loss: 2764632320.0000 - mae: 17048.2129 - val_loss: 2916045056.0000 - val_mae: 16617.1426\n",
            "Epoch 41/50\n",
            "\u001b[1m3681/3681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - loss: 2965231360.0000 - mae: 17180.1953 - val_loss: 2913330432.0000 - val_mae: 16610.5352\n",
            "Epoch 42/50\n",
            "\u001b[1m3681/3681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - loss: 2665288960.0000 - mae: 17002.8594 - val_loss: 2913103616.0000 - val_mae: 16721.3633\n",
            "Epoch 43/50\n",
            "\u001b[1m3681/3681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3ms/step - loss: 2327239936.0000 - mae: 16874.3691 - val_loss: 2912686592.0000 - val_mae: 16805.0137\n",
            "Epoch 44/50\n",
            "\u001b[1m3681/3681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - loss: 3220859648.0000 - mae: 17459.2402 - val_loss: 2912409088.0000 - val_mae: 16610.8848\n",
            "Epoch 45/50\n",
            "\u001b[1m3681/3681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - loss: 2996209152.0000 - mae: 17404.9473 - val_loss: 2915187200.0000 - val_mae: 16580.5430\n",
            "Epoch 46/50\n",
            "\u001b[1m3681/3681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5ms/step - loss: 2842969088.0000 - mae: 17155.9062 - val_loss: 2911845888.0000 - val_mae: 16609.9473\n",
            "Epoch 47/50\n",
            "\u001b[1m3681/3681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - loss: 2628835328.0000 - mae: 16931.2754 - val_loss: 2914512640.0000 - val_mae: 16348.4414\n",
            "Epoch 48/50\n",
            "\u001b[1m3681/3681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - loss: 3609480704.0000 - mae: 17325.5137 - val_loss: 2912080640.0000 - val_mae: 16625.6055\n",
            "Epoch 49/50\n",
            "\u001b[1m3681/3681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - loss: 2168716544.0000 - mae: 16742.7559 - val_loss: 2915208704.0000 - val_mae: 17450.6035\n",
            "Epoch 50/50\n",
            "\u001b[1m3681/3681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - loss: 2913114368.0000 - mae: 17313.2305 - val_loss: 2911492096.0000 - val_mae: 16909.5488\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
            "ANN MSE: 3091886086.48227\n",
            "ANN R2 Score: 0.16210317249232242\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Model Performance:\n",
        "\n",
        "The MSE is quite high, indicating that the model's predictions are significantly different from the actual values.\n",
        "\n",
        "The R2 score of 0.162 suggests that the model is only explaining about 16% of the variance in the data. This is a low score, meaning the model is not capturing the underlying patterns in the dataset effectively.\n",
        "\n",
        "Implications:\n",
        "\n",
        "A high MSE combined with a low R2 score points to poor model fit, implying that the ANN is not making accurate predictions and might not generalize well to unseen data.\n"
      ],
      "metadata": {
        "id": "2DTp4j2wVU1h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary module\n",
        "!pip install scikeras\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "75HzrXvpTRU7",
        "outputId": "c1439d92-57e9-46d5-80e1-639ac14a74eb"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikeras\n",
            "  Downloading scikeras-0.13.0-py3-none-any.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from scikeras) (3.4.1)\n",
            "Collecting scikit-learn>=1.4.2 (from scikeras)\n",
            "  Downloading scikit_learn-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (13.8.0)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (3.11.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (0.12.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (0.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (24.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras>=3.2.0->scikeras) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->scikeras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->scikeras) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->scikeras) (0.1.2)\n",
            "Downloading scikeras-0.13.0-py3-none-any.whl (26 kB)\n",
            "Downloading scikit_learn-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m59.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scikit-learn, scikeras\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.3.2\n",
            "    Uninstalling scikit-learn-1.3.2:\n",
            "      Successfully uninstalled scikit-learn-1.3.2\n",
            "Successfully installed scikeras-0.13.0 scikit-learn-1.5.1\n"
          ]
        }
      ]
    },
    {
      "source": [
        "# Import the necessary module\n",
        "from scikeras.wrappers import KerasRegressor # Use Scikeras instead of tensorflow.keras.wrappers.scikit_learn\n",
        "\n",
        "# Voting Regressor with ANN\n",
        "# Wrap ann_model with KerasRegressor\n",
        "vtr_ann = VotingRegressor(estimators=[('xgboost', xgb_model), ('lightgbm', lgb_model), ('ann', KerasRegressor(build_fn=create_ann_model))])\n",
        "vtr_ann.fit(scaler.fit_transform(x_train), y_train)\n",
        "y_pred_vtr_ann = vtr_ann.predict(scaler.transform(x_test))"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXUtTAN3S-q6",
        "outputId": "c0f83b9d-1b7e-4e8c-bc27-b5ef3186c577"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4601/4601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - loss: 3201067520.0000 - mae: 22739.7461\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation with ANN\n",
        "mse_vtr_ann = mean_squared_error(y_test, y_pred_vtr_ann)\n",
        "print(\"Voting Regressor with ANN MSE:\", mse_vtr_ann)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_MyjTZKPCg6",
        "outputId": "87ab3582-f83a-4aff-a141-be2861ac7f53"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Voting Regressor with ANN MSE: 3062428597.8454475\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The result of the Voting Regressor with ANN yielding an MSE (Mean Squared Error) of 3,062,428,597.85 suggests that the model's predictions are still quite far from the actual values. This high MSE indicates that the model may not be performing well in capturing the relationship between the input features and the target variable (price in this case).\n",
        "\n",
        "#Conclusion:\n",
        "Model Performance: The high MSE signifies that the ensemble model, even with the inclusion of ANN, is not accurate. There may be a need for further optimization in terms of feature engineering, model tuning, or data preprocessing.\n"
      ],
      "metadata": {
        "id": "aN4Js-L6UX0L"
      }
    }
  ]
}